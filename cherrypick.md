### 2

你需要在公有云上运行一个大数据相关批处理任务。这时候你来到阿里云界面上，准备买几台虚拟机。但是玲琅满目的可选虚拟机的配置，让你不知道应该选哪种配置好。如果买最高的配置吧，费用又太高了（毕竟阿里云也不便宜）。如果买低配吧，可能程序运行的时间又会太慢了。这时候，就可以用CherryPick了。你输入你的预算花费、能够接受的程序运行时间，CherryPick就能给你推荐一个花费少、时间短的机器配置。

### 3

在如今，越来越多的大数据分析在云端运行，比如说有Map－Reduce、深度学习等等。这些应用在提交时，需要选择所需的机器配置。但是一般数据科学家们并不知道如果选择机器配置。据统计，在同样的运行时间下，不同的机器配置所需的花费，最多相差了12倍。因此一个自动的预测推荐功能是有存在的价值的。

### 5

如图1所示，SparkML（具有固定数量的CPU内核）上的回归作业在256GBRAM上运行时间返回减少。这是因为工作并不能从更多的RAM中获益。因此，运行时间只能看到边际改善。

图2显示了在不同的群集大小上对 SparkML运行回归的成本, 其中每个 vm 在 aws ec2 中附带 15GB的 ram 和4个内核。我们可以看到, 当我们向集群中添加更多资源时, 成本不会单调增加或减少。这是因为添加资源可能会加快计算速度, 但也会提高运行时间的单位价格。

图3显示了 spark 上 tpc-ds 和回归的不同形状, 以及它们与实例类型的关系。对于 terasort, 低内存实例 (8 核和 15 gb 的 ram) 执行得最好, 因为 cpu 是一个更关键的资源。另一方面, 对于回归, 由于缺乏 ram, 同一群集的运行时间是最佳候选群集的2.4倍。

### 7

1.通过构建任务模型来预测

通过对Job本身结构的分析，来对其结构上建模。现在还挺多工作是按照这个方法来的，比如说Ernest(NSDI’16)，就将所有类型的任务分成了几种模型（一对多，多对多等等），然后求出一个整体模型来进行预测。本文的作者也说了，这种方法存在弊端，并不是通用的模型（如SQL like情况下Ernest效果比较差）。同时呢，也需要对任务本身的结构进行深入分析，如果分析的不好的话，建模也建不好，不太稳定。

### 8

2.静态查找最佳的配置
 这种方法就是直接试不同的配置会有什么样的效果。这样的方法就是需要试很多种不同的配置，对系统的负载会很大，花的时间会比较长。但是这种的好处就是把Job当黑盒来处理，不用深入研究Job本身的特性。

### 10

对于给定的应用程序和工作负载, 目标是找到满足性能要求并最大限度地降低总执行成本的最佳或近乎最佳的云配置。在形式上, 文章使用 t (̇x) 来表示应用程序及其输入工作负载的运行时函数。运行时间取决于云配置配置矢量̇x, 其中包括实例类型、cpu、ram 和其他资源配置。了解所有候选云配置下的 t (̇x) 将使求解 eqn (1) 变得很简单, 但成本很高, 因为需要尝试所有候选配置。相反, 文章使用 bo 直接搜索 eqn (1) 的近似解, 其成本要小得多。

### 11

图显示了性能建模和配置搜索的联合过程。从一些初始云配置（例如，三个）开始，运行它们，并将配置细节和作业完成时间输入到性能模型中。然后，根据性能模型动态地选择要运行的下一个云配置，并将结果反馈给性能模型。

### 12

贝叶斯优化（BO）〔13, 28, 33〕是解决Eqn等优化问题的一个框架。（1）目标函数C（x）事先未知，但可以通过实验观察到。通过将C(x)建模为随机过程，例如高斯过程[26]，BO可以根据从C(x)获得的一个或多个样本来计算C(x)的置信区间。置信区间是C（x）曲线最有可能（例如，95%概率）通过的区域。例如，在图5（a）中，虚线是实际函数C（x）。在X1和X2的两个样本中，BO计算标记有蓝色阴影区域的置信区间。黑实线表示C(x)的期望值，每个输入点_x处的C(x)的值以95%的概率落在置信区间内。在_x3(图5(b))和_x4(图5(c))取新样本后，更新置信区间(贝叶斯定理的后验分布)，并且随着置信区间面积的减小，C(x)的估计值提高。